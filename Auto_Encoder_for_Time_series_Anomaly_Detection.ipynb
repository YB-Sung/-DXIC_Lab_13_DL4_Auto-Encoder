{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YB-Sung/DXIC_Lab_13_DL4_Auto-Encoder/blob/main/Auto_Encoder_for_Time_series_Anomaly_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [ LG전자 H&A DX Intensive Course - Auto-Encoder for Anomaly Detection ]\n",
        "\n",
        "Auto-Encoder를 활용한 time-series anomaly detection"
      ],
      "metadata": {
        "id": "ihXL84IZP7Ii"
      },
      "id": "ihXL84IZP7Ii"
    },
    {
      "cell_type": "markdown",
      "id": "db0072fa",
      "metadata": {
        "id": "db0072fa"
      },
      "source": [
        "# Import modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "feea49a2",
      "metadata": {
        "id": "feea49a2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import Adam, SGD\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from itertools import groupby, accumulate\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "custom_params = {\"axes.spines.right\": False, \"axes.spines.top\": False}\n",
        "sns.set_theme(style=\"ticks\", rc=custom_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b33cd08a",
      "metadata": {
        "id": "b33cd08a"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fe9b15d",
      "metadata": {
        "id": "7fe9b15d"
      },
      "outputs": [],
      "source": [
        "def torch_seed(random_seed):\n",
        "    torch.manual_seed(random_seed)\n",
        "    torch.cuda.manual_seed(random_seed)\n",
        "    torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
        "    # CUDA randomness\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    np.random.seed(random_seed)\n",
        "    random.seed(random_seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(random_seed)\n",
        "\n",
        "\n",
        "def train(\n",
        "    model, dataloader, criterion, optimizer, log_interval: int, device: str) -> list:\n",
        "\n",
        "    total_loss = []\n",
        "\n",
        "    model.train()\n",
        "    for i, (inputs, _) in enumerate(dataloader):\n",
        "\n",
        "        # convert device\n",
        "        inputs = inputs.to(device)\n",
        "\n",
        "        # model outputs\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # loss\n",
        "        loss = criterion(inputs, outputs).mean()\n",
        "        total_loss.append(loss.item())\n",
        "\n",
        "        # calculate gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # update model weights\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # log learning history\n",
        "        if i % log_interval == 0 or (i+1) == len(dataloader):\n",
        "            print(f\"{'TRAIN':5s} [{i+1:5d}/{len(dataloader):5d}] loss: {np.mean(total_loss):.4f}\")\n",
        "\n",
        "    # average loss\n",
        "    avg_loss = np.mean(total_loss)\n",
        "\n",
        "    return avg_loss\n",
        "\n",
        "def test(\n",
        "    model, dataloader, criterion, log_interval: int, device: str) -> list:\n",
        "\n",
        "    # for auroc\n",
        "    total_loss = []\n",
        "    total_inputs = []\n",
        "    total_targets = []\n",
        "    total_outputs = []\n",
        "\n",
        "    torch_seed(223)\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, targets) in enumerate(dataloader):\n",
        "            # get inputs and targets\n",
        "            total_inputs.extend(inputs.numpy())\n",
        "            total_targets.extend(targets.numpy())\n",
        "\n",
        "            # convert device\n",
        "            inputs = inputs.to(device)\n",
        "\n",
        "            # model outputs\n",
        "            outputs = model(inputs)\n",
        "            total_outputs.extend(outputs.cpu().numpy())\n",
        "\n",
        "            # loss\n",
        "            loss = criterion(inputs, outputs).max(dim=-1)[0]\n",
        "            total_loss.extend(loss.cpu().numpy())\n",
        "\n",
        "            # log learning history\n",
        "            if i % log_interval == 0 or (i+1) == len(dataloader):\n",
        "                print(f\"{'TSET':5s} [{i+1:5d}/{len(dataloader):5d}] loss: {np.mean(total_loss):.4f}\")\n",
        "\n",
        "    # total inputs, outputs, targets and loss\n",
        "    total_inputs = np.concatenate(total_inputs, axis=0)\n",
        "    total_outputs = np.concatenate(total_outputs, axis=0)\n",
        "    total_targets = np.array(total_targets).reshape(-1)\n",
        "    total_loss = np.array(total_loss).reshape(-1)\n",
        "\n",
        "    # auroc\n",
        "    if sum(total_targets) == 0:\n",
        "        auroc = 1.\n",
        "    else:\n",
        "        auroc = roc_auc_score(total_targets, total_loss)\n",
        "\n",
        "    # return\n",
        "    return auroc, total_inputs, total_outputs, total_loss\n",
        "\n",
        "\n",
        "def fit(\n",
        "    model, trainloader, testloader, criterion, optimizer,\n",
        "    epochs: int, log_interval: int, device: str) -> list:\n",
        "\n",
        "    train_history = []\n",
        "    test_history_auroc = []\n",
        "\n",
        "    # fitting model\n",
        "    for i in range(epochs):\n",
        "        print(f'\\nEpoch: [{i+1}/{epochs}]')\n",
        "        train_loss = train(\n",
        "            model        = model,\n",
        "            dataloader   = trainloader,\n",
        "            criterion    = criterion,\n",
        "            optimizer    = optimizer,\n",
        "            log_interval = log_interval,\n",
        "            device       = device\n",
        "        )\n",
        "\n",
        "        test_auroc, total_inputs, total_outputs, total_loss = test(\n",
        "            model        = model,\n",
        "            dataloader   = testloader,\n",
        "            criterion    = criterion,\n",
        "            log_interval = log_interval,\n",
        "            device       = device\n",
        "        )\n",
        "\n",
        "        print(f'\\nTest AUROC: {test_auroc:.4f}')\n",
        "\n",
        "        # show results\n",
        "        plt.figure(figsize=(15,4))\n",
        "        sns.lineplot(x=range(len(total_inputs)), y=total_inputs[:,0], label='inputs')\n",
        "        sns.lineplot(x=range(len(total_outputs)), y=total_outputs[:,0], label='reconstruction')\n",
        "        sns.lineplot(x=range(len(total_loss)), y=total_loss, label='anomaly score')\n",
        "\n",
        "        # set title\n",
        "        plt.title(\"testset anomal score\")\n",
        "        plt.xlabel(\"time index\")\n",
        "        plt.ylabel(\"value\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # stack history\n",
        "        train_history.append(train_loss)\n",
        "        test_history_auroc.append(test_auroc)\n",
        "\n",
        "    return train_history, test_history_auroc\n",
        "\n",
        "\n",
        "def figure(\n",
        "    all_train_history: list, all_test_history_auroc: list, all_exp_name: list) -> None:\n",
        "\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(15,7))\n",
        "\n",
        "    # train line plot\n",
        "    for i, (train_h, exp_name) in enumerate(zip(all_train_history, all_exp_name)):\n",
        "        sns.lineplot(\n",
        "            x     = range(1, len(train_h)+1),\n",
        "            y     = train_h,\n",
        "            label = exp_name,\n",
        "            ax    = ax[0]\n",
        "        )\n",
        "\n",
        "    # test AUROC lineplot\n",
        "    for i, (test_h, exp_name) in enumerate(zip(all_test_history_auroc, all_exp_name)):\n",
        "        sns.lineplot(\n",
        "            x     = range(1, len(test_h)+1),\n",
        "            y     = test_h,\n",
        "            label = exp_name,\n",
        "            ax    = ax[1]\n",
        "        )\n",
        "\n",
        "\n",
        "    # set y axis label\n",
        "    ax[0].set_ylabel('MSE Loss')\n",
        "    ax[1].set_ylabel('AUROC')\n",
        "\n",
        "    # set x axis label\n",
        "    ax[0].set_xlabel('Epochs')\n",
        "    ax[1].set_xlabel('Epochs')\n",
        "\n",
        "    # set title\n",
        "    ax[0].set_title('Train loss history')\n",
        "    ax[1].set_title('Test AUROC history')\n",
        "\n",
        "    # set y value limit\n",
        "    max_train = np.max(all_train_history)\n",
        "\n",
        "    ax[0].set_ylim(0, max_train+0.01)\n",
        "    ax[1].set_ylim(0, 1)\n",
        "\n",
        "    # set legend\n",
        "    ax[0].legend(loc='upper left')\n",
        "    ax[1].legend(loc='upper left')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1033d254",
      "metadata": {
        "id": "1033d254"
      },
      "source": [
        "# Configuration for experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7e112de",
      "metadata": {
        "id": "d7e112de"
      },
      "outputs": [],
      "source": [
        "class Config:\n",
        "    # dataset 관련 parameters\n",
        "    window = 100\n",
        "    stride = 10\n",
        "\n",
        "    # make dataset\n",
        "    sin_sequence = 100\n",
        "    repeat = 30\n",
        "\n",
        "    # synthesis anomaly setting\n",
        "    anomaly_sequence = 10\n",
        "    anomaly_region = 5\n",
        "\n",
        "    # training 관련 parameters\n",
        "    epochs = 20\n",
        "    batch_size = 8\n",
        "    test_batch_size = 128\n",
        "    learning_rate = 0.001\n",
        "    num_workers = 2\n",
        "    log_interval = 2000\n",
        "\n",
        "    # device\n",
        "    device = 'cuda'\n",
        "\n",
        "    # seed\n",
        "    seed = 223\n",
        "\n",
        "cfg = Config()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9187001e",
      "metadata": {
        "id": "9187001e"
      },
      "source": [
        "## make dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30532b65",
      "metadata": {
        "id": "30532b65"
      },
      "outputs": [],
      "source": [
        "# trainset\n",
        "x_train = np.array([np.sin(i*np.pi) for i in np.linspace(start=-2, stop=2, num=cfg.sin_sequence)] * cfg.repeat)\n",
        "x_train = x_train + np.random.random(cfg.sin_sequence * cfg.repeat)\n",
        "y_train = np.zeros(len(x_train))\n",
        "\n",
        "# testset\n",
        "x_test = x_train[:1000].copy()\n",
        "y_test = np.zeros(len(x_test))\n",
        "\n",
        "torch_seed(cfg.seed)\n",
        "anomaly_idx = np.random.choice(range(len(x_test)), size=cfg.anomaly_region)\n",
        "\n",
        "for ano_idx in anomaly_idx:\n",
        "    x_test[ano_idx:ano_idx+cfg.anomaly_sequence] = x_test[ano_idx:ano_idx+cfg.anomaly_sequence] * 2\n",
        "    y_test[ano_idx:ano_idx+cfg.anomaly_sequence] = 1\n",
        "\n",
        "# plot\n",
        "fig, ax = plt.subplots(2,1,figsize=(15,7))\n",
        "sns.lineplot(x=range(len(x_train)), y=x_train, ax=ax[0])\n",
        "ax[0].set_title('trainset values')\n",
        "ax[0].set_xlabel('time index')\n",
        "ax[0].set_ylim([-2, 4])\n",
        "\n",
        "sns.lineplot(x=range(len(x_test)), y=x_test, ax=ax[1])\n",
        "for ano_idx in anomaly_idx:\n",
        "    ax[1].axvspan(ano_idx, ano_idx+cfg.anomaly_sequence, color='red', alpha=0.2)\n",
        "ax[1].set_title('testset values')\n",
        "ax[1].set_xlabel('time index')\n",
        "ax[1].set_ylim([-2, 4])\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05ed64d5",
      "metadata": {
        "id": "05ed64d5"
      },
      "outputs": [],
      "source": [
        "class TSADDataset(Dataset):\n",
        "    def __init__(self, X: np.ndarray, y: np.ndarray, window: int, stride: int):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "        self.window = window\n",
        "        self.stride = stride\n",
        "\n",
        "        # start index\n",
        "        self.start_index = list(range(0, len(self.X) - cfg.window + 1, self.stride))\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        s_idx = self.start_index[idx]\n",
        "        input = self.X[s_idx:s_idx+self.window]\n",
        "        target = self.y[s_idx:s_idx+self.window]\n",
        "\n",
        "        input = torch.FloatTensor(input).unsqueeze(-1)\n",
        "\n",
        "        return input, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.start_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a66c2af5",
      "metadata": {
        "id": "a66c2af5"
      },
      "outputs": [],
      "source": [
        "trainset = TSADDataset(\n",
        "    X      = x_train,\n",
        "    y      = y_train,\n",
        "    window = cfg.window,\n",
        "    stride = cfg.stride\n",
        ")\n",
        "\n",
        "testset = TSADDataset(\n",
        "    X      = x_test,\n",
        "    y      = y_test,\n",
        "    window = cfg.window,\n",
        "    stride = cfg.window\n",
        ")\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=cfg.batch_size, shuffle=True, num_workers=cfg.num_workers)\n",
        "testloader = DataLoader(testset, batch_size=cfg.test_batch_size, shuffle=False, num_workers=cfg.num_workers)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa13c0e8",
      "metadata": {
        "id": "fa13c0e8"
      },
      "source": [
        "# RNN Auto-Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d87337d",
      "metadata": {
        "id": "5d87337d"
      },
      "outputs": [],
      "source": [
        "class RNNAutoEncoder(nn.Module):\n",
        "    def __init__(self, input_dim: int, hidden_size: int, num_layers: int):\n",
        "        super().__init__()\n",
        "\n",
        "        # encoder\n",
        "        self.enc = nn.RNN(\n",
        "            input_size  = input_dim,\n",
        "            hidden_size = hidden_size,\n",
        "            num_layers  = num_layers,\n",
        "            batch_first = True\n",
        "        )\n",
        "\n",
        "        # decoder\n",
        "        self.dec = nn.RNN(\n",
        "            input_size  = input_dim,\n",
        "            hidden_size = hidden_size,\n",
        "            num_layers  = num_layers,\n",
        "            batch_first = True\n",
        "        )\n",
        "\n",
        "        self.output = nn.Linear(in_features=hidden_size, out_features=input_dim)\n",
        "\n",
        "    def encoder(self, x):\n",
        "        out, hidden = self.enc(x)\n",
        "\n",
        "        return out, hidden\n",
        "\n",
        "    def decoder(self, x, hidden):\n",
        "        out, hidden = self.dec(x, hidden)\n",
        "        out = self.output(out)\n",
        "\n",
        "        return out, hidden\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len, dims = x.size()\n",
        "\n",
        "        # encoder\n",
        "        out, hidden = self.encoder(x)\n",
        "\n",
        "        # decoder\n",
        "        x_rec = torch.zeros_like(x).to(x.device)\n",
        "        x_dec = torch.zeros((batch_size, 1, dims), dtype=torch.float).to(x.device)\n",
        "        for i in range(seq_len):\n",
        "            out_dec_i, hidden = self.decoder(x_dec, hidden)\n",
        "            x_rec[:,i,:] = out_dec_i[:,0,:]\n",
        "            x_dec = out_dec_i\n",
        "\n",
        "        return x_rec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7196738",
      "metadata": {
        "id": "b7196738"
      },
      "outputs": [],
      "source": [
        "torch_seed(cfg.seed)\n",
        "rae = RNNAutoEncoder(input_dim=1, hidden_size=32, num_layers=2)\n",
        "rae.to(cfg.device)\n",
        "print('load RNN Auto-Encoder')\n",
        "print('The number of model parameters: ',sum([p.numel() for p in rae.parameters()]))\n",
        "\n",
        "criterion = nn.MSELoss(reduction='none')\n",
        "optimizer = Adam(rae.parameters(), lr=cfg.learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be6386a4",
      "metadata": {
        "scrolled": false,
        "id": "be6386a4"
      },
      "outputs": [],
      "source": [
        "torch_seed(cfg.seed)\n",
        "train_history_rae, test_history_auroc_rae = fit(\n",
        "    model        = rae,\n",
        "    trainloader  = trainloader,\n",
        "    testloader   = testloader,\n",
        "    criterion    = criterion,\n",
        "    optimizer    = optimizer,\n",
        "    epochs       = cfg.epochs,\n",
        "    log_interval = cfg.log_interval,\n",
        "    device       = cfg.device\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66dcfb20",
      "metadata": {
        "id": "66dcfb20"
      },
      "outputs": [],
      "source": [
        "all_train_history = [train_history_rae]\n",
        "all_test_history_auroc = [test_history_auroc_rae]\n",
        "all_exp_name = ['RAE']\n",
        "\n",
        "figure(\n",
        "    all_train_history      = all_train_history,\n",
        "    all_test_history_auroc = all_test_history_auroc,\n",
        "    all_exp_name           = all_exp_name\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f671f63d",
      "metadata": {
        "id": "f671f63d"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bef8355",
      "metadata": {
        "id": "4bef8355"
      },
      "outputs": [],
      "source": [
        "trainset = TSADDataset(\n",
        "    X      = x_train,\n",
        "    y      = y_train,\n",
        "    window = cfg.window,\n",
        "    stride = cfg.window\n",
        ")\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=cfg.batch_size, shuffle=False, num_workers=cfg.num_workers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16d684df",
      "metadata": {
        "id": "16d684df"
      },
      "outputs": [],
      "source": [
        "_, total_inputs, total_outputs, total_loss = test(\n",
        "    model        = rae,\n",
        "    dataloader   = trainloader,\n",
        "    criterion    = criterion,\n",
        "    log_interval = cfg.log_interval,\n",
        "    device       = cfg.device\n",
        ")\n",
        "\n",
        "# show results\n",
        "fig, ax = plt.subplots(figsize=(30,5))\n",
        "\n",
        "sns.lineplot(x=range(len(total_inputs)), y=total_inputs[:,0], label='inputs', ax=ax)\n",
        "sns.lineplot(x=range(len(total_outputs)), y=total_outputs[:,0], label='reconstruction', ax=ax)\n",
        "ax.set_title('train results', size=20)\n",
        "ax.set_xlabel('time index', size=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a648f43",
      "metadata": {
        "id": "3a648f43"
      },
      "outputs": [],
      "source": [
        "def anomaly_region(anomaly_score, threshold):\n",
        "    indices = list(accumulate(len(list(g)) for i,g in groupby((anomaly_score > threshold))))\n",
        "    starts = indices[:len(indices)//2*2:2]\n",
        "    stops = [i-1 for i in indices[1::2]]\n",
        "\n",
        "    return starts, stops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be8a8101",
      "metadata": {
        "id": "be8a8101"
      },
      "outputs": [],
      "source": [
        "_, total_inputs, total_outputs, total_loss = test(\n",
        "    model        = rae,\n",
        "    dataloader   = testloader,\n",
        "    criterion    = criterion,\n",
        "    log_interval = cfg.log_interval,\n",
        "    device       = cfg.device\n",
        ")\n",
        "\n",
        "# show results\n",
        "fig, ax = plt.subplots(3,1, figsize=(15,7))\n",
        "\n",
        "sns.lineplot(x=range(len(total_inputs)), y=total_inputs[:,0], label='inputs', ax=ax[0])\n",
        "sns.lineplot(x=range(len(total_outputs)), y=total_outputs[:,0], label='reconstruction', ax=ax[0])\n",
        "sns.lineplot(x=range(len(total_loss)), y=total_loss, label='anomaly score', ax=ax[0])\n",
        "ax[0].set_title('test result')\n",
        "ax[0].set_xlabel('time index')\n",
        "\n",
        "# ground truth\n",
        "sns.lineplot(x=range(len(total_inputs)), y=total_inputs[:,0], label='inputs', ax=ax[1])\n",
        "for ano_idx in anomaly_idx:\n",
        "    ax[1].axvspan(ano_idx, ano_idx+cfg.anomaly_sequence, color='red', alpha=0.2)\n",
        "ax[1].set_title('ground truth anomaly regions')\n",
        "ax[1].set_xlabel('time index')\n",
        "\n",
        "\n",
        "# anomaly regions\n",
        "sns.lineplot(x=range(len(total_inputs)), y=total_inputs[:,0], label='inputs', ax=ax[2])\n",
        "starts, stops = anomaly_region(total_loss, threshold=0.5)\n",
        "for start_idx, end_idx in zip(starts, stops):\n",
        "    ax[2].axvspan(start_idx, end_idx, color='green', alpha=0.2)\n",
        "ax[2].set_title('prediction anomaly regions')\n",
        "ax[2].set_xlabel('time index')\n",
        "\n",
        "\n",
        "# set title\n",
        "plt.title(\"testset anomal score\")\n",
        "plt.xlabel(\"time index\")\n",
        "plt.ylabel(\"value\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5IugzHGaIzF0"
      },
      "id": "5IugzHGaIzF0",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}